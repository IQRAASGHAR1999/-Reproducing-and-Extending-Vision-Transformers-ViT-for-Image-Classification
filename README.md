# Reproducing and Extending Vision Transformers (ViT) for Image Classification

This project reproduces the Vision Transformer (ViT) architecture and benchmarks it against classical CNNs on CIFAR-10. Extensions and custom experiments are encouraged!

## ðŸ“š Project Goals

- Implement ViT (with [timm](https://github.com/huggingface/pytorch-image-models) or from scratch)
- Train and evaluate on CIFAR-10
- Compare with ResNet
- Visualize results and attention maps
- Try extensions: data augmentation, transfer learning, or different datasets

## ðŸ“¦ Structure

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train_vit.py           # Training script for ViT
â”‚   â”œâ”€â”€ train_cnn.py           # Training script for CNN baseline
â”‚   â””â”€â”€ dataset.py             # Data handling utilities
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ analysis.ipynb         # For visualization, EDA, and results
â”œâ”€â”€ data/                      # Datasets (downloaded/processed)
â”œâ”€â”€ results/                   # Saved models, plots, metrics
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

## ðŸš€ Getting Started

1. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Train Vision Transformer**
   ```bash
   python src/train_vit.py
   ```

3. **Train CNN Baseline**
   ```bash
   python src/train_cnn.py
   ```

4. **Analyze Results**
   - Open `notebooks/analysis.ipynb`

## ðŸ“Š Results

- Compare accuracy, loss, and other metrics in `results/`
- Visualize attention maps in the notebook

## ðŸ“„ References

- [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)

---
